import os
import sys
import speech_recognition as sr
from faster_whisper import WhisperModel
from llama_cpp import Llama

# --- CONFIGURATION ---
# V√©rifie bien que ce fichier existe !
MODEL_LLM_PATH = "models/Qwen2.5-7B-Instruct-Q4_K_M.gguf"
WHISPER_SIZE = "medium"
TEMP_AUDIO_FILE = "temp_audio.wav"

# --- 1. CHARGEMENT DES MOD√àLES ---
print("‚è≥ Initialisation du syst√®me...")

print("   1/2 Chargement de l'Oreille (Whisper)...")
try:
    ear_model = WhisperModel(WHISPER_SIZE, device="cpu", compute_type="int8")
except Exception as e:
    print(f"‚ùå Erreur Whisper : {e}")
    sys.exit(1)

print("   2/2 Chargement du Cerveau (LLM)...")
try:
    # n_ctx=2048 est suffisant et plus rapide que 4096
    brain_model = Llama(
        model_path=MODEL_LLM_PATH,
        n_ctx=2048,
        n_gpu_layers=0,
        verbose=False
    )
except Exception as e:
    print(f"‚ùå Erreur LLM : {e}")
    sys.exit(1)

# PROMPT SYST√àME AM√âLIOR√â (V2)
SYSTEM_PROMPT = """
R√îLE: Tu es "Sensei", un professeur de langue oral expert (Fran√ßais, Anglais, Japonais, Cor√©en).

TES DIRECTIVES P√âDAGOGIQUES :
1. ANALYSE L'INTENTION :
   - Si l'user demande une traduction -> Traduis directement sans blabla.
   - Si l'user essaie de parler la langue -> Corrige-le.

2. R√àGLES DE POLITESSE (CRITIQUE) :
   - Japonais/Cor√©en : Force toujours le registre "Poli Standard" (Desu/Masu, Yo).
   - SI l'user est vulgaire ou impoli (ex: "Omae", "Baka") -> NE TRADUIS PAS. Dis-lui gentiment que c'est inappropri√©.

3. FORMAT DE R√âPONSE (Oral) :
   - Fais des r√©ponses COURTES (1 ou 2 phrases max).
   - Ne r√©p√®te pas syst√©matiquement "Je comprends ce que tu veux dire". Varie tes r√©ponses.
   - Si tu corriges, donne la phrase correcte et demande de r√©p√©ter.
"""

history = [{"role": "system", "content": SYSTEM_PROMPT}]
recognizer = sr.Recognizer()

# --- 2. BOUCLE DE CONVERSATION ---
print("\n" + "="*50)
print("üéôÔ∏è  SENSEI EST PR√äT ! (Parlez dans le micro)")
print("="*50 + "\n")

while True:
    try:
        # A. √âcoute du microphone
        with sr.Microphone() as source:
            if len(history) == 1:
                print("Calibrage du micro (silence svp)...")
                recognizer.adjust_for_ambient_noise(source, duration=1)

            print("\nüëÇ J'√©coute... (Parlez maintenant)")
            audio_data = recognizer.listen(source, timeout=None)

            print("‚è≥ Traitement audio...")
            with open(TEMP_AUDIO_FILE, "wb") as f:
                f.write(audio_data.get_wav_data())

        # B. Transcription
        segments, info = ear_model.transcribe(TEMP_AUDIO_FILE, beam_size=5)
        user_text = "".join([segment.text for segment in segments]).strip()

        if not user_text:
            print("‚ö†Ô∏è Je n'ai rien entendu.")
            continue

        print(f"üìù Vous avez dit ({info.language}) : \033[96m{user_text}\033[0m")

        if any(word in user_text.lower() for word in ["stop", "quitter", "exit"]):
            print("Au revoir !")
            break

        # C. R√©flexion (LLM)
        history.append({"role": "user", "content": user_text})

        print("ü§ñ Sensei r√©fl√©chit...", end="\r")
        output = brain_model.create_chat_completion(
            messages=history,
            temperature=0.6, # Plus bas = plus pr√©cis, moins d'hallucinations
            max_tokens=150   # R√©ponses plus courtes pour aller plus vite
        )
        response = output['choices'][0]['message']['content']

        # D. R√©ponse
        print(f"ü§ñ Sensei : \033[92m{response}\033[0m")
        history.append({"role": "assistant", "content": response})

    except KeyboardInterrupt:
        print("\nArr√™t manuel.")
        break
    except Exception as e:
        print(f"\n‚ùå Erreur : {e}")
        # Si c'est PyAudio qui manque, on le saura ici
        if "PyAudio" in str(e):
            print("üí° Conseil : Essaie 'pip install pipwin' puis 'pipwin install pyaudio'")

if os.path.exists(TEMP_AUDIO_FILE):
    os.remove(TEMP_AUDIO_FILE)