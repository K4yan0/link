import sys
from llama_cpp import Llama

# --- CONFIGURATION ---
MODEL_PATH = "models/Qwen2.5-7B-Instruct-Q4_K_M.gguf"

print("ðŸ§  Chargement du cerveau (Mode Hybride Conversationnel)...")

try:
    llm = Llama(
        model_path=MODEL_PATH,
        n_ctx=2048,       # On garde 2048 pour la vitesse en local (suffisant pour le MVP)
        n_gpu_layers=0,
        verbose=False
    )
except Exception as e:
    print(f"âŒ Erreur : {e}")
    sys.exit(1)

# --- PROMPT V3 : L'Ã‰QUILIBRE PARFAIT ---
SYSTEM_PROMPT = """
RÃ”LE: Tu es un Ami Polyglotte qui aide l'utilisateur Ã  apprendre par la pratique.
LANGUES : FranÃ§ais, Anglais, Japonais (Poli/Desu-Masu), CorÃ©en (Poli/Yo).

DIRECTIVES PRIORITAIRES :
1. ANALYSE D'ABORD, RÃ‰PONDS ENSUITE :
   - Si l'utilisateur fait une erreur : Corrige-le avec la mÃ©thode "Sandwich" (Compliment -> Correction -> "RÃ©pÃ¨te aprÃ¨s moi").
   - Si la phrase est correcte (ou aprÃ¨s la correction) : RÃ‰PONDS Ã€ LA QUESTION ou JOUE LE JEU DE RÃ”LE.

2. EXEMPLE DE COMPORTEMENT (CAS JEU DE RÃ”LE) :
   - User : "Bonjour, que voulez-vous manger ?"
   - Toi : "C'est une phrase parfaite ! Je voudrais un hamburger et une salade, s'il vous plaÃ®t."
   (Tu ne t'arrÃªtes pas Ã  la correction, tu continues la conversation).

3. GESTION DES INSULTES :
   - Si l'user est vulgaire (ex: "Baka", "Omae"), dis calmement : "Attention, c'est un terme blessant. Utilise plutÃ´t [Terme Poli] si tu veux Ãªtre respectÃ©."

4. TONALITÃ‰ :
   - Sois encourageant mais naturel. Pas de phrases robots.
"""

def chat_loop():
    history = [
        {"role": "system", "content": SYSTEM_PROMPT}
    ]

    print("\nâœ… SENSEI EST PRÃŠT (Mode Conversation) !")
    print("------------------------------------------------")

    while True:
        try:
            user_input = input("\nToi : ")
            if user_input.lower() in ["exit", "quit"]:
                break

            history.append({"role": "user", "content": user_input})

            print("Sensei : (Ã©crit...)", end="\r")

            output = llm.create_chat_completion(
                messages=history,
                temperature=0.7, # On remonte un peu pour qu'il soit plus imaginatif en jeu de rÃ´le
                max_tokens=250,
                repeat_penalty=1.1
            )

            response_text = output['choices'][0]['message']['content']

            print(f"Sensei : {response_text}" + " " * 20)

            history.append({"role": "assistant", "content": response_text})

        except KeyboardInterrupt:
            break

if __name__ == "__main__":
    chat_loop()